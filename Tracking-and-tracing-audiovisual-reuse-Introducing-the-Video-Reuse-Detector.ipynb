{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "": []
     }
    },
    "tags": [
     "title"
    ]
   },
   "source": [
    "# Tracking and tracing audiovisual reuse: Introducing the Video Reuse Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "contributor"
    ]
   },
   "source": [
    "## Tomas  Skotare [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/ORCID_ID) \n",
    "Humlab, Umeå University."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "contributor"
    ]
   },
   "source": [
    "## Pelle  Snickars [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/0000-0001-5122-1549) \n",
    "Department of Art and Cultural Sciences, Lund University."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "contributor"
    ]
   },
   "source": [
    "## Maria  Eriksson [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/0000-0002-7534-4268) \n",
    "Department of Arts, Media, Philosophy, University of Basel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "abstract"
    ]
   },
   "source": [
    "The cultural reuse and reappropriation of audiovisual content has been a recurring topic of research in the humanities, not least in studies of remix cultures. An open question that remains, however, is how artificial intelligence and machine learning may help scholars study the reuse and reappropriation of audiovisual heritage. In this article, we introduce the Video Reuse Detector (VRD) – a methodological toolkit for identifying visual similarities in audiovisual archives with the help of machine learning. Designed to assist in the study of the “social life” and “cultural biographies” (<cite data-cite=\"1971321/6PBSUNC7\"></cite>, <cite data-cite=\"1971321/N7PZTCJU\"></cite>) of video clips, the VRD helps explore how the meaning of historic footage changes when it circulates and is recycled/cross-referenced in video productions through time. The toolkit uses machine learning techniques (specifically, convolutional neural networks), combined with tools for performing similarity searches (specifically, the Faiss library) to detect copies and near-copies in audiovisual archives. It also assembles a series of tools for trimming and preparing datasets and filtering/visualizing matching results (such as introducing similarity thresholds, filtering based on sequential matches of frames, and visually viewing the final matching results). Inspired by the “visual turn” in digital history and digital humanities research, the article will introduce the basic logic and rationale behind the VRD, exemplify how the toolkit works, and discuss how the digitization of audiovisual archives open for new ways of exploring the reuse of historic moving images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "This section will provide a general introduction to the article, discuss previous research concerning cultural reuse, and provide insights into state-of-the-art uses of machine learning/CNN's in historic research, focusing on research that deals with visiual content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "Chapter 3 will then guide the reader through the practical application of the toolkit in textual/narrative/descriptive form, while ***chapter 4 consists of a technical demo that showcases how the toolkit works. It is this demo that should be tested during the technical check.*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "In chapter 5, we present a more complex demonstration of what the toolkit can do. Here, however, we work with datasets that cannot be publically released. Thus, the case study discussed in chapter 5 will presented in the form of images/texts. While not directly reproducible for readers, we hope that this study will illustrate the potentials and pitfalls of using CNN's to study cultural reuse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "# VRD introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "The VRD is a methodological toolkit for identifying visual similarities in audiovisual archives with the help of machine learning. It has been assembled because of the lack of open source solutions for audiovisual copy detection and is meant to help archivists and humanistic scholars study video reuse. The toolkit was originally developed within the research project European History Reloaded: Curation and Appropriation of Digital Audiovisual Heritage, funded by the JPI Cultural Heritage project, EU Horizon 2020 research and innovation program. Its main developer is Tomas Skotare, with assistance from Maria Eriksson and Pelle Snickars. The toolkit is open-source, handles all video formats supported by the FFmpeg framework, and is built to be used in Jupyter Notebooks. It can be downloaded as a docker container () and the source code is openly available on Github ()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "In what follows, we introduce how the toolkit functions. We also present a demo where the VRD is applied to two videos that are openly available on [Archive.org](https://archive.org/). The first video, entitled [*The Eagle Has Landed: The Flight of Apollo 11*](https://archive.org/details/gov.archives.arc.45017), contains footage from the first moon landing in July 1969, and was released by the U.S. National Aeronautics and Space Administration (NASA) in the same year. The second video, entitled [The Moon and Us](https://archive.org/details/journey-through-the-solar-system-episode-06-the-moon-us), consists of Episode 6 from the documentary series *Journey Through the Solar System* which was also produced by NASA. First released in 1983, the series contains footage from various Apollo missions, incuding Apollo 11. Both clips are roughly 30 minutes long and are used in compliance with their respective licenses. Before uploading the videos on Github for this demo, we compressed them with HEVC in order to stay within Github's allowed file size of 100 MB/file. The videos can be seen by running the code cells below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://archive.org/embed/gov.archives.arc.45017\" \n",
       "width=\"320\" height=\"240\" frameborder=\"0\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Watch The Eagle Has Landed: The Flight of Apollo 11\n",
    "%%HTML\n",
    "<iframe src=\"https://archive.org/embed/gov.archives.arc.45017\" \n",
    "width=\"320\" height=\"240\" frameborder=\"0\"></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://archive.org/details/journey-through-the-solar-system-episode-06-the-moon-us\" \n",
       "width=\"320\" height=\"240\" frameborder=\"0\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Watch The Moon and Us\n",
    "# Journey Through the Solar System\n",
    "# Episode 6\n",
    "%%HTML\n",
    "<iframe src=\"https://archive.org/details/journey-through-the-solar-system-episode-06-the-moon-us\" \n",
    "width=\"320\" height=\"240\" frameborder=\"0\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "## Step 1. Extract frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "The VRD performs its similarity searches in four main steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "To begin with, the VRD includes tools for dividing audiovisual content into still frames. Digital videos generally contain 24-30 frames per second and the VRD is instructed to extract one frame per second of video by default. It is these still images that constitute the VRD's main object of analysis. This means that parts of the VRD can also be used to study digital images in general (incl. photographs, computer animations etc.), although the toolkit presented here is customized to deal with moving images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "## Step 2. Produce fingerprints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "Second, the VRD uses a so-called Convolutional Neural Network-–or CNN-–to extract the key visual features found in each frame. We call these extracted visual features 'fingerprints'. CNN's constitue a common technique for studying visual imagery with the help of artificial intelligence. Modelled to imitate the connectivity pattern of neurons in the visual cortex of animals, neural networks are used in areas such as facial recognition, medical imaging, and autonomous driving. We decided to work with CNN’s after doing multiple tests with more traditional tools for visual content recognition, including image hashing and video fingerprinting with help of [ORB](https://docs.opencv.org/3.4/d1/d89/tutorial_py_orb.html) (Oriented FAST and rotated BRIEF)-–a method for extracting and comparing visual features in images. CNN’s quickly outperformed the ORB technology’s ways of identifying visual similarities in video content, however, both in terms of accuracy and processing speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "It is beyond the scope of this article to explain how CNN's work in depth (for more information on this, a good place to start is [Wikipedia](https://en.wikipedia.org/wiki/Convolutional_neural_network)), but we make a couple of remarks regarding the technology's basic technical structure. While the detailed technical workings of individual CNN's differ, neural networks are broadly designed according to multiple layers of analysis and abstraction. Each layer in a CNN will process an input and produce an output, which is passed on to the next layer. For instance, one layer in a CNN may observe how pixels are spatially arranged in an image and search for areas with a high contrast between nearby pixels (a good marker for what is visually unique in a picture), while another layer might focus on reducing what information is stored about pixel contrasts (instructing the model to “forget” all areas in a picture with a lower pixel contrast than a given value, for example). In this way, the CNN produces a successively smaller and hopefully more precise map of the analyzed image. Somewhere before the final layer of a CNN is reached, the network will produce a highly compressed interpretation of the key visual characteristics of images. It is then common for the remaining layers in a CNN to classify what appears in the image, for instance by recognizing faces and objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "In our case, the VRD applies a CNN to process individual frames but stops when a compressed yet sufficiently complex interpretation of the key visual features of an image has been produced. Again, we call these compressed interpretations fingerprints and the VRD will use them to find patterns of similarity across videos. In more detail, the VRD will export data in the form of vectors from a given layer in a CNN. These vectors mirror the visual charachteristics found in the original frames. A vector is a mathematical quantity that discloses the magnitude (or length) and direction of a geometric object. In other words, we can say that fingerprints are mathematical abstractions that carry information about what is visually unique in each frame. What is good about fingerprints is that their detailed yet highly abstracted information can be used to recognize visual similarities even if a video has been modified or distorted. For instance, frames can be recognized as similar even if someone has adjusted their color, resolution, or composition. This is useful when studying cultural remix practices, for example. "
   ]
  },
  {
   "attachments": {
    "layer%20example3.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "![layer%20example3.jpg](attachment:layer%20example3.jpg)\n",
    "\n",
    "Image 1. Example of what a processed frame can look like when extracted from an intermediate layer in a CNN, before it is converted into vectors. In this example, the CNN ResNet50 was used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "When the VRD extracts its vectors/fingerprints from a given intermediate layer in a CNN––something that is otherwise done to visualize the learning process of a CNN, for example––the remaining layers of a neural net are not evaluated (more about this in the [Keras documentation](https://keras.io/getting_started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer-feature-extraction)). We partly do this to save time/computing power, and partly because we are not interested in classifying the content in images. Instead, we essentially use a CNN to compress and vectorize video frames. It is important to understand that this is not how CNN's are normally used. Therefore, we also know comparatively little about which CNN and extraction layer is best suited for the task. Commonly, the performance of CNN's are evaluated based on tests such as the [ImageNet Large Scale Visual Recognition Challenge](https://www.image-net.org/challenges/LSVRC/), where a neural network's capacity recognize objects/faces in images is compared against human beings's ways of performing the same task. Tests such as the ImageNet Challenge are not designed to evaluate a CNN's ability to compress and vectorize frames, however. When looking at previous evaluations of CNN's and deciding what neural network to use (see [Keras documentation](https://keras.io/api/applications/)), we have therefore mainly searched for CNN's that are relatively new and perform well in over-all tests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "The current version of VRD is based on TensorFlow2, which includes the open source Keras API. [TensorFlow2](https://www.tensorflow.org/) is an open-source machine learning platform and software library for working with machine learning and artificial intelligence. It was originally developed by Google and can be used for multiple purposes, including the training and inference deep neural networks such as CNN's. The [Keras API](https://keras.io/about/) is is a deep learning API that runs on top of the TensorFlow platform. Keras functions as an interface for solving machine learning problems and provides building blocks for using machine learning methods. We use version 2.11.0 of the Keras API which makes 11 pre-trained convolutional neural networks available for use. All of these networks are open source and can easily be applied in the VRD. We mainly decided to work with pre-trained neural nets since it was unfeasible for our small research team to train a new network from scratch. Furthermore, we found that many of the neural nets in the Keras API succeeded in producing vectors that were compressed yet detailed enough to study video reuse, without needing to be re-trained our fine-tuned. Hence, we decided to work with the networks directly in their original form. Re-training the networks on relevant datasets would likely further improve the performance of the VRD, however. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "Initially, we mainly worked with the neural network [ResNet50](https://keras.io/api/applications/resnet/) (see Snickars et.al. 2023) but later switched to a network called [EfficientNetB4](https://keras.io/api/applications/efficientnet/), which is newer and performs better in accuracy tests. EfficientNet was first released by engineers at Google Research's so-called Brain Team in 2019 (<cite data-cite=\"1971321/K5A3FXNI\"></cite>), and at the time of this article's writing, it existed in seven different versions (see [Keras documentation](https://keras.io/api/applications/efficientnet/)). We have found that version B4––which lies in the mid-range in the tradeoff between accuracy and speed among the EfficientNet versions––works well for the purpose of identifying video reuse. The current version of the VRD applies EfficientNetB4 *as is* (that is, without any re-training) and extracts its fingerprints from a layer called 'block7b_se_squeeze'. This layer is found towards the end of the network model (at the time of this article's writing, layer 463 out of 476). When deciding where to extract our fingerprint vectors, we wanted to find a layer that contained complex interpretations of the visual features in frames, yet produced vectors that were sufficiently compressed to work with large datasets. In addition, we wanted to find a layer where the neural network had not started to apply its object classification too strictly. In our tests, Block7b_se_squeeze appeared to live up to these qualifications. Importantly, however, we recommend exploring the use of other layers (and CNN's) when using the VRD, as we have not performed any comprehensive performance tests of all CNN's in the Keras API and their respective layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "## Step 3. Calculate similarity neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "After saving extracted fingerprints in a database, the VRD applies its third step, where the so-called [Faiss library](https://faiss.ai/) is used to calculate the closest simiarity neighbours for each fingerprint. Faiss is an open source software library that specializes in large-scale similarity searches. First released by Facebook AI Research in 2018, it efficiently clusters dense vectors and conducts large-scale similarity searches. For instance, Faiss can be run on Graphical Processing Units (GPU’s) which provides significant advantages in terms of speed. As an open [Faiss manual](https://www.pinecone.io/learn/faiss-tutorial/) explains, Faiss will index a given set of vectors and then use another vector (called the query vector) to search for the most similar vectors within the index. Faiss allows for determining which vectors are similar by measuring the Euclidean distance between *all* given points within an index using an index called IndexFlatL2. IndexFlatL2 performs a so-called *exhaustive* search and is very accurate in its evaluation of vector similarity, but slow since it matches/compares *every* point in the index (in our case, fingerprints) against the other, one by one. To speed up this process, the Faiss index contains several methods for optimizing similarity searches, although these will always be implemented at the cost of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "For instance, it is possible to optimize the speed of a Faiss similarity search by partitioning the index (i.e. limiting the search scope to *approximate* similarity, rather than calculating an absolute similarity), or by way of so-called quantization, which involves compressing the size of vectors (more about this [here](https://www.pinecone.io/learn/faiss-tutorial/)). When the Faiss index has determined (or approximated) the similarities found within an index, it will output a so-called distance metric to each compared set of vectors. This is a value that indicates how closely related their features are, according to Faiss. A low distance metric value (or short distance) indicates high similarity and a high distance metric value (or long distance) indicates low similarity. The distance metric 0.0 represents the absolute closest similarity Faiss can ascribe to two compared vectors, and essentially corresponds to the distance that a vector would have to itself (i.e. an absolute match)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "While Faiss can be used for any sort of similarity search, the VRD uses it to identify visual similarities between frame fingerprints. In particular, the VRD will apply IndexFlatL2 to perform an exhaustive search and compare all fingerprints against each other, without optimizing the similarity search. While this is costly in terms of speed/processing power, it allows the VRD to later find sequential matches in the analyzed videos--a feature that is central for how the toolkit works. It is possible for VRD users to overwrite the use of IndexFlatL2 and instead use the Faiss library's optimization methods. However, this implies that the VRD's current structure for outputting final matching results in the form of sequential matches will be lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "To save time/memory and minimize the display of poor similarity matches, the Faiss index comes with a default setting that only shows the 100 closest neighbours for each analyzed vector. While it is generally desired to limit the amount of neighbours shown for each vector, this threshold comes with drawbacks because of how the VRD is built. More specifically, it is important to note that the threshold is applied ***before*** the VRD runs another filter that removes all matches from the same video. This can cause problems if a video contains a lot of still images or slow visual movements, since long sequeces of frames from the same video could then be given a very low distance metric. In such cases, a frame's 100 closest neighbours may be occupied by lots of frames from the same video, while other relevant matching results are \"pushed\" out of the top 100 list. When all matches from the same video are filtered out from the top 100 similarity neighbours, important matches could thus be lost. While it would be preferrable to filter matches from the same video *before* distance metrics are calculated and exported, the Faiss library does unfortunately not support this feature at the moment (a problem that has also been noted by [others on Github](https://github.com/facebookresearch/faiss/issues/40), for example). It is, however, possible to adjust the 100 nearest neighbour threshold to reduce the risk of filtering out interesting matching results. This is done in the VRD, as the threshold is increased from 100 to 250 by default. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "The distance metrics produced by the FAISS library constitute a core element of the VRDs evaluation of visual similarity, although it is important to note one final thing, namely that these metrics are dynamic and will change/flucuate depending on which dataset is processed. For instance, the quality of the source material and the number of images/frames in the dataset will affect how distance metrics are distributed. Likewise, the distribution of distance metrics are highly affected by which neural network and neural network layer is used. This means that there is no absolute value or threshold that indicates what distance metric value corresponds to a \"correct\" or \"actual\" instance of reuse. Instead, any use of the VRD will always involve manually exploring how each project's unique distance metric values correspond to actual visual likenesses in the source material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "## Step 4.  Filter matching results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "When the distance metrics for each fingerprint's similarity neighbours have been calculcated, the VRD reaches its forth and final step of image processing. In this step, it is possible to narrow down the search results with the help of two major filtering features. To begin with, it is possible to implement a general distance metric threshold before the final matching results are shown. For instance, the VRD may be instructed to only show fingerprint neighbours with a distance metric below the value 30 000. If this threshold is accurate (again, manual exploration is always necessary here), it should greatly reduce the number of shown non-matching frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "Second, the VRD includes a feature for applying what we call 'sequential filtering'. We define a sequence as an instance where two or more sequential fingerprints (i.e. frames that were extracted one after the other from the original file) from two videos have been given a distance metric below a specified value. If frame 1-6 in Video X and frame 11-16 in Video Y are each given a distance metric below the threshold 20 000, for example, this may be defined as a sequential match. Sequential filtering is used to identify instances when longer chunks of moving images have been reused and we assume that such chunks are more interesting to users than individual matching frames. Furthermore, we have found that sequential matches are generally of better quality (i.e. more indicative of actual reuse) than individual matching frames, since there is a higher likelihood that actual cases of reuse have been found when at least two frames in a row have been assigned a low distance metric. Sequential filtering is implemented by deciding the minimum sequential length (or duration in seconds/frames) of shown fingerprint neigbours. It is also possible to instruct the VRD to 'tolerate' that a given number of frames within a sequence deviates from the assigned distance metric threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "To summarize, the VRD thus performs its similarity search by processing audiovisual content in three main steps: as original video files are converted to still frames, as still frames are converted to fingerprints, and as fingerprints are plotted as similarity neigbours. Alternatively, one could describe this process as a matter of compressing, converting, abstracting 'raw' audiovisual content to frames, frames to vectors, and vectors to distance metrics. Furthermore, the VRD contains tools for narrowing down the search results, including features for implementing distance metric thresholds and applying sequential filtering. The final matching results are displayed in diagrams, tables, and frame previews. On the whole, these matching results are meant to function as a guide that point users towards videos that might be interesting to study manually in more detail. In other words, we strongly advise against exporting and using diagrams, tables, and thumbnail comparisons as absolute proof of video reuse and instead emphasize the need double-check the VRD's search results. The VRD should be approached as an assistance tool in navigating large video datasets. As will become evident in our explorations of reuse in the SF-archive, this is not least due to the weaknesses and pitfalls that the toolkit brings with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "To test the VRD demo, move to the article's hermeneutics layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "# VRD demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "In what follows, we demonstrate the technical functioning of the VRD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "## Similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "We begin by importing a series of necessary modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# we disable tensorflow warnings as they are verbose\n",
    "# if things do not work, this suppression should be removed\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "from vrd import neural_networks, vrd_project, faiss_helper\n",
    "from vrd.neural_networks import NeuralNetworks\n",
    "from vrd.sequence_finder import SequenceFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "We also need to install ffmpeg since it is a prerequisite for ffmpeg-python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://deb.debian.org/debian bullseye InRelease\n",
      "Hit:2 http://deb.debian.org/debian-security bullseye-security InRelease\n",
      "Hit:3 http://deb.debian.org/debian bullseye-updates InRelease\n",
      "Reading package lists... Done3m\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "84 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.3.5-0+deb11u1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 84 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# Question for the technical check: \n",
    "# are we allowed to embed this in the docker file \n",
    "# when submitting the final article?\n",
    "!apt update\n",
    "!apt install -y ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "Next, we start a new project and give it a name. We also inform the VRD where to locate the video files we want to work with and choose to apply with the neural network EfficientNetB4 from the Keras API. We also decide to export vectors/fingerprints from a layer called Block7b_se_squeeze in EfficientNetB4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "# set project configuration\n",
    "demo_project = vrd_project.VRDProject(\n",
    "    name = 'demo_project', \n",
    "    project_base_path=\"./vrd_projects/\",\n",
    "    video_path = 'media/demo/', \n",
    "    network = neural_networks.NeuralNetworks.efficientnetb4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "We then extract one frame per second from each video file. These frames are saved in the project directory, under the frames subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defe8ff52f3542608a77d14e66e9f461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract frames\n",
    "demo_project.initialize_frame_extractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "Next, we use EfficientNetB4 to create a fingerprint for each extracted frame and use these to populate the fingerprint database. The database is saved as 'database_file' in the project directory. Note that it is important to delete any pre-existing databases and start over if another CNN is used. This is done by specifying force_recreate=True. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'demo_project' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30/3397945853.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# above line does not work and the printed layer is 462\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# after looking at the source the following worked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdemo_project\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m463\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# suggestion to get rid of the force_recreate argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'demo_project' is not defined"
     ]
    }
   ],
   "source": [
    "# create fingerprints\n",
    "demo_project.populate_fingerprint_database(force_recreate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "Next, we create a Faiss index of the fingerprints and save it as faiss_index in the project directory. If this has already been done once, the VRD will fetch the saved index. Note that if any changes are done to the source material (i.e. the videos, frames, or fingerprints) or the selected CNN model it is necessary to recreate the index by setting force_recreate to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "# index fingerprints using Faiss\n",
    "demo_project.initialize_faiss_index(force_recreate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "We then instruct Faiss to calculate the closest similarity neighbours for each fingerprint. We instruct Faiss to output the 250 closest neigbours for each fingerprint and these will be saved in the \"neighbour_batch\" subdirectory in the project directory. The VRD will apply Faiss IndexFlatL2 as is (i.e. perform an exhaustive search where all fingerprints in the index are compared against each other). To change this setting and make use of the Faiss library's similarity search optimization, changes have to be made to the source code. Note, however, that this will imply that the VRD's ways of finding sequential matches is lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "# calculate similarity neighbours\n",
    "demo_project.neighbours_considered = 250\n",
    "demo_project.initialize_neighbours(force_recreate = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "## Analyze distance metric distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "Before we apply some final filters, we analyze the distribution of distance metric values in a historgram to get an idea of where it might be suitable to place a distance metric threshold. If the threshold is placed too low, interesting matching results may get lost. If the threshold is placed too high, there is a risk of being shown a high number of uninteresting matches. We recommend placing the threshold around the point where the histogram indicates a sharp increase in found neighbours. In the image example below, this would imply setting the distance metric threshold around 50 000, to start with. It is always possible to go back, change the threshold (selected in upcoming section 4.3), and rerun all subsequent code cells at a later stage."
   ]
  },
  {
   "attachments": {
    "distance%20metric%20illustration.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "![distance%20metric%20illustration.jpg](attachment:distance%20metric%20illustration.jpg)\n",
    "\n",
    "Image 2. Example of where to set the threshold in the analysis of a distance metric histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "# get distance histogram\n",
    "demo_project.neighbours.get_distance_histogram();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "## Configure filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "Finally, we configure some filters to narrow down the search results. We apply a shortest sequence threshold (in seconds), set a maximum distance metric threshold for all found sequential matches, and decide how many frames should be allowed to deviate from this threshold in a sequence (see 'allow skip' configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "# configure filters\n",
    "SHORTEST_SEQUENCE = 2\n",
    "MAX_DISTANCE      = 60000\n",
    "ALLOW_SKIP        = 2\n",
    "\n",
    "\n",
    "### Nothing to change below this line! ###\n",
    "\n",
    "finder = SequenceFinder(\n",
    "    demo_project.neighbours, \n",
    "    max_distance=MAX_DISTANCE)\n",
    "\n",
    "finder.filter_matches_from_same_video()\n",
    "\n",
    "sequences = finder.find_sequences(\n",
    "    shortest_sequence=SHORTEST_SEQUENCE, \n",
    "    allow_skip=ALLOW_SKIP,\n",
    "    combine_overlap=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "## Output matching results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "We then have a look at the final sequential matching results in the form of frame thumbnails. The longest found sequences will be show first. We can limit number of sequences we want to be shown and adjust the frame size to suit our dataset. The metadata above each row of thumbnails can be used to manually find the sequences in the original files, as the disclosed start/end time notifies where the frames where found in the source videos. By looking at the mean distance column, we can also get an idea of how to adjust the distace metric threshold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "Note that the final version of the article will include some additional visualisations and ways of filtering/sorting the matching results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "hermeneutics"
    ]
   },
   "outputs": [],
   "source": [
    "# show notebook sequences\n",
    "finder.show_notebook_sequence(sequences,show_limit=100, frame_resize=(30,30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics",
     "narrative"
    ]
   },
   "source": [
    "## Potentials and pitfalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics",
     "narrative"
    ]
   },
   "source": [
    "Here, we will discuss the potentials and pitfalls of using the tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "# VRD case study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "Here, we will present the results of the case study. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "# Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "narrative"
    ]
   },
   "source": [
    "<div class=\"cite2c-biblio\"></div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "citation-manager": {
   "items": {}
  },
  "cite2c": {
   "citations": {
    "1971321/6C4DNEI4": {
     "DOI": "10.5749/movingimage.17.2.0071",
     "URL": "https://www.jstor.org/stable/10.5749/movingimage.17.2.0071",
     "accessed": {
      "day": 31,
      "month": 3,
      "year": 2020
     },
     "author": [
      {
       "family": "Barbara Flueckiger",
       "given": ""
      }
     ],
     "container-title": "The Moving Image: The Journal of the Association of Moving Image Archivists",
     "id": "1971321/6C4DNEI4",
     "issue": "2",
     "issued": {
      "year": 2017
     },
     "language": "en",
     "page": "71",
     "page-first": "71",
     "title": "A Digital Humanities Approach to Film Colors",
     "type": "article-journal",
     "volume": "17"
    },
    "1971321/6PBSUNC7": {
     "author": [
      {
       "family": "Kopytoff",
       "given": "Igor"
      }
     ],
     "container-title": "The Social Life of Things: Commodities in Cultural Perspective",
     "editor": [
      {
       "family": "Appadurai",
       "given": "Arjun"
      }
     ],
     "event-place": "Cambridge",
     "id": "1971321/6PBSUNC7",
     "issued": {
      "year": 1986
     },
     "page": "64-94",
     "page-first": "64",
     "publisher": "Cambridge University Press",
     "publisher-place": "Cambridge",
     "title": "The Social Life of Things: Commodities in Cultural Perspective",
     "type": "chapter"
    },
    "1971321/DHJJL7VR": {
     "DOI": "10.1093/digitalsh/fqz013",
     "URL": "https://academic.oup.com/dsh/advance-article/doi/10.1093/digitalsh/fqz013/5382183",
     "accessed": {
      "day": 20,
      "month": 3,
      "year": 2020
     },
     "author": [
      {
       "family": "Arnold",
       "given": "Taylor"
      },
      {
       "family": "Tilton",
       "given": "Lauren"
      }
     ],
     "container-title": "Digital Scholarship in the Humanities",
     "id": "1971321/DHJJL7VR",
     "issued": {
      "year": 2019
     },
     "language": "en",
     "shortTitle": "Distant viewing",
     "title": "Distant viewing: analyzing large visual corpora",
     "title-short": "Distant viewing",
     "type": "article-journal",
     "volume": "34"
    },
    "1971321/F98YWULX": {
     "author": [
      {
       "family": "Moretti",
       "given": "Franco"
      }
     ],
     "event-place": "London & New York",
     "id": "1971321/F98YWULX",
     "issued": {
      "year": 2013
     },
     "publisher": "Verso",
     "publisher-place": "London & New York",
     "title": "Distant Reading",
     "type": "book"
    },
    "1971321/H43PIJW7": {
     "author": [
      {
       "family": "Bowker",
       "given": "Geoffrey C."
      }
     ],
     "container-title": "Raw Data Is an Oxymoron",
     "editor": [
      {
       "family": "Gitelman",
       "given": "Lisa"
      }
     ],
     "event-place": "Cambridge & London",
     "id": "1971321/H43PIJW7",
     "issued": {
      "year": 2013
     },
     "page": "167-172",
     "page-first": "167",
     "publisher": "MIT Press",
     "publisher-place": "Cambridge & London",
     "title": "Data Flakes: An Afterword to \"Raw Data Is an Oxymoron\"",
     "type": "chapter"
    },
    "1971321/K5A3FXNI": {
     "URL": "http://arxiv.org/abs/1905.11946",
     "abstract": "Convolutional Neural Networks (ConvNets) are commonly developed at a ﬁxed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefﬁcient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet.",
     "accessed": {
      "day": 22,
      "month": 2,
      "year": 2023
     },
     "author": [
      {
       "family": "Tan",
       "given": "Mingxing"
      },
      {
       "family": "Le",
       "given": "Quoc V."
      }
     ],
     "id": "1971321/K5A3FXNI",
     "issued": {
      "day": 11,
      "month": 9,
      "year": 2020
     },
     "language": "en",
     "note": "arXiv:1905.11946 [cs, stat]",
     "publisher": "arXiv",
     "shortTitle": "EfficientNet",
     "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks",
     "title-short": "EfficientNet",
     "type": "article"
    },
    "1971321/N7PZTCJU": {
     "author": [
      {
       "family": "Appadurai",
       "given": "Arjun"
      }
     ],
     "container-title": "The Social Life of Things: Commodities in Cultural Perspective",
     "editor": [
      {
       "family": "Appadurai",
       "given": "Arjun"
      }
     ],
     "event-place": "Cambridge",
     "id": "1971321/N7PZTCJU",
     "issued": {
      "year": 1986
     },
     "publisher": "Cambridge University Press",
     "publisher-place": "Cambridge",
     "title": "Introduction: Commodities and the Politics of Value",
     "type": "chapter"
    },
    "1971321/WM98NSC7": {
     "ISBN": "978-0-521-35726-5",
     "edition": "11. print",
     "editor": [
      {
       "family": "Appadurai",
       "given": "Arjun"
      }
     ],
     "event-place": "Cambridge",
     "id": "1971321/WM98NSC7",
     "issued": {
      "year": 2013
     },
     "language": "en",
     "note": "Meeting Name: Ethnohistory workshop\nOCLC: 935348822",
     "number-of-pages": "329",
     "publisher": "Cambridge Univ. Press",
     "publisher-place": "Cambridge",
     "shortTitle": "The social life of things",
     "title": "The social life of things: commodities in cultural perspective",
     "title-short": "The social life of things",
     "type": "book"
    },
    "1971321/XVEENKLM": {
     "DOI": "10.1093/llc/fqy085",
     "URL": "https://academic.oup.com/dsh/advance-article/doi/10.1093/llc/fqy085/5296356",
     "accessed": {
      "day": 17,
      "month": 2,
      "year": 2021
     },
     "author": [
      {
       "family": "Wevers",
       "given": "Melvin"
      },
      {
       "family": "Smits",
       "given": "Thomas"
      }
     ],
     "container-title": "Digital Scholarship in the Humanities",
     "id": "1971321/XVEENKLM",
     "issue": "1",
     "issued": {
      "day": 18,
      "month": 1,
      "year": 2019
     },
     "language": "en",
     "page": "194-207",
     "page-first": "194",
     "shortTitle": "The visual digital turn",
     "title": "The visual digital turn: Using neural networks to study historical images",
     "title-short": "The visual digital turn",
     "type": "article-journal",
     "volume": "35"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
